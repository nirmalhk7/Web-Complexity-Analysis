{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276 websites scanned\n"
     ]
    }
   ],
   "source": [
    "with open(\"./output.json\") as file:\n",
    "    websites = json.load(file)\n",
    "website_len=len(websites)\n",
    "print(\"{} websites scanned\".format(website_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Glimpse of Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c3983aa18e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mrank_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rank\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# for request in site[\"reqdetails\"]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Average Rank\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "# Between Classified/Unclassified and Available/Unavailable\n",
    "info = {\n",
    "    \"Unclassified but Available\": 0,\n",
    "    \"Classified but Unavailable (Not 200)\": 0,\n",
    "    \"Classified and Available\": 0,\n",
    "    \"Unclassified and Unavailable (Not 200)\": 0,\n",
    "    \"Repeated Websites\":0,\n",
    "    \"Average Rank\":0\n",
    "}\n",
    "rank_arr=[]\n",
    "webdetails={}\n",
    "webcategory={}\n",
    "mime_used={}\n",
    "for index,site in enumerate(websites):\n",
    "    try:\n",
    "        webdetails[site[\"name\"]]+=1\n",
    "    except:\n",
    "        webdetails[site[\"name\"]]=1\n",
    "    try:\n",
    "        webcategory[site[\"category\"]]+=1\n",
    "    except:\n",
    "        webcategory[site[\"category\"]]=1\n",
    "    if(site[\"category\"]==\"Unclassified\"):\n",
    "        if(site[\"reqcode\"]==\"N/A\"):\n",
    "            info[\"Unclassified and Unavailable (Not 200)\"]+=1\n",
    "        else:\n",
    "            info[\"Unclassified but Available\"]+=1\n",
    "    else:\n",
    "        if(site[\"reqcode\"]==\"N/A\"):\n",
    "            info[\"Classified but Unavailable (Not 200)\"]+=1\n",
    "        else:\n",
    "            info[\"Classified and Available\"]+=1\n",
    "    if(webdetails[site[\"name\"]]>1):\n",
    "        info[\"Repeated Websites\"]+=1\n",
    "    info[\"Average Rank\"]+=site[\"rank\"]\n",
    "    rank_arr.append((site[\"rank\"],index))\n",
    "    # for request in site[\"reqdetails\"]:\n",
    "info[\"Average Rank\"]//=count\n",
    "for t in info.keys():\n",
    "    print(\"{} : {}\".format(t,info[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category-wise splitup:\n",
      "Unclassified: 162\n",
      "Entertainment: 7\n",
      "Business/Economy: 27\n",
      "Technology/Internet: 14\n",
      "Health: 8\n",
      "Suspicious: 4\n",
      "News: 2\n",
      "Education: 3\n",
      "Sports/Recreation: 3\n",
      "Shopping: 4\n",
      "Society/Daily Living: 1\n",
      "Audio/Video Clips: 2\n",
      "Government/Legal: 4\n",
      "Reference: 5\n",
      "Real Estate: 1\n",
      "Charitable/Non-Profit: 3\n",
      "Gambling: 1\n",
      "Newsgroups/Forums: 2\n",
      "Pornography: 1\n",
      "Finance: 1\n",
      "Office/Business Applications: 1\n",
      "Travel: 7\n",
      "Restaurants/Food: 3\n",
      "Software Downloads: 2\n",
      "TV/Video Streams: 1\n",
      "Social Networking: 2\n",
      "Media Sharing: 2\n",
      "Games: 1\n",
      "Brokerage/Trading: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCategory-wise splitup:\")\n",
    "for t in webcategory.keys():\n",
    "    print(\"{}: {}\".format(t,webcategory[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998531, 78): Max Rank\n"
     ]
    }
   ],
   "source": [
    "rank_arr.sort(key=lambda x:x[0])\n",
    "print(\"{}: Max Rank\".format(rank_arr[len(rank_arr)-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating Websites into Buckets\n",
    "Because we didnt have the complete means to collect the data, we've not been able to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def buckets_generate(arr,count):\n",
    "    old_chunk=[]\n",
    "    for i in range(0,website_len,10):\n",
    "        chunk=list(chunks(arr,website_len-i))\n",
    "        if(len(old_chunk)>=count and len(chunk)!=len(old_chunk)):\n",
    "            return old_chunk\n",
    "        old_chunk=chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 0: 76 websites from rank 2 to 76591\n",
      "Bucket 1: 76 websites from rank 76729 to 164356\n",
      "Bucket 2: 76 websites from rank 164838 to 371716\n",
      "Bucket 3: 48 websites from rank 383298 to 998531\n"
     ]
    }
   ],
   "source": [
    "buckets=buckets_generate(rank_arr,4)\n",
    "for index,bucket in enumerate(buckets):\n",
    "    print(\"Bucket {}: {} websites from rank {} to {}\".format(index,len(bucket),min(bucket[0][0],bucket[len(bucket)-1][0]),max(bucket[0][0],bucket[len(bucket)-1][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Complexity\n",
    "### Number of Object Requests Made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.w3resource.com/graphics/matplotlib/basic/matplotlib-basic-exercise-5.php\n",
    "def num_of_req(bucket):\n",
    "    for b_det in bucket:\n",
    "        count=0\n",
    "        site=websites[b_det[1]]\n",
    "        for req in site[\"reqdetails\"]:\n",
    "            count+=req[\"method\"]==\"GET\"\n",
    "        print(\"{} websites {} GET requests\".format(site[\"name\"],count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook.com websites 51 GET requests\n",
      "youtube.com websites 62 GET requests\n",
      "microsoft.com websites 20 GET requests\n",
      "twitter.com websites 28 GET requests\n",
      "tmall.com websites 0 GET requests\n",
      "instagram.com websites 23 GET requests\n",
      "netflix.com websites 0 GET requests\n",
      "linkedin.com websites 5 GET requests\n",
      "baidu.com websites 0 GET requests\n",
      "qq.com websites 0 GET requests\n",
      "windowsupdate.com websites 0 GET requests\n",
      "wikipedia.org websites 6 GET requests\n",
      "apple.com websites 48 GET requests\n",
      "live.com websites 43 GET requests\n",
      "quizizz.com websites 87 GET requests\n",
      "irecommend.ru websites 137 GET requests\n",
      "masrawy.com websites 0 GET requests\n",
      "coupons.com websites 0 GET requests\n",
      "xmtrading.com websites 35 GET requests\n",
      "uns.ac.id websites 0 GET requests\n",
      "doda.jp websites 0 GET requests\n",
      "alphacoders.com websites 129 GET requests\n",
      "comingsoon.net websites 0 GET requests\n",
      "360kan.com websites 224 GET requests\n",
      "openai.com websites 22 GET requests\n",
      "infn.it websites 0 GET requests\n",
      "vananews.com websites 3 GET requests\n",
      "geoguessr.com websites 127 GET requests\n",
      "estrepublicain.fr websites 0 GET requests\n",
      "fapesp.br websites 41 GET requests\n",
      "flyasiana.com websites 0 GET requests\n",
      "militaryonesource.mil websites 0 GET requests\n",
      "radar.io websites 60 GET requests\n",
      "cinematoday.jp websites 309 GET requests\n",
      "movistar.com.ar websites 0 GET requests\n",
      "guardiacivil.es websites 107 GET requests\n",
      "bchydro.com websites 41 GET requests\n",
      "wdzj.com websites 0 GET requests\n",
      "stromectolmed.com websites 0 GET requests\n",
      "mvcr.cz websites 44 GET requests\n",
      "linear.com websites 55 GET requests\n",
      "dumskaya.net websites 61 GET requests\n",
      "clickscot.com websites 0 GET requests\n",
      "scriptinstall.rocks websites 0 GET requests\n",
      "wzytautoparts.com websites 0 GET requests\n",
      "hitosara.com websites 240 GET requests\n",
      "fantasyfootballcalculator.com websites 45 GET requests\n",
      "omu.edu.tr websites 0 GET requests\n",
      "thrillophilia.com websites 35 GET requests\n",
      "lambrides.org websites 41 GET requests\n",
      "essaycastle.co.uk websites 106 GET requests\n",
      "cnbetacdn.com websites 0 GET requests\n",
      "pamyat-naroda.ru websites 90 GET requests\n",
      "soscisurvey.de websites 11 GET requests\n",
      "aboutkidshealth.ca websites 110 GET requests\n",
      "researchtoolkit.org websites 0 GET requests\n",
      "sdqoi2d.com websites 0 GET requests\n",
      "wavesplatform.com websites 30 GET requests\n",
      "aixifan.com websites 0 GET requests\n",
      "privateislandsonline.com websites 0 GET requests\n",
      "accengage.com websites 133 GET requests\n",
      "appfigures.com websites 50 GET requests\n",
      "prsformusic.com websites 67 GET requests\n",
      "sep.ir websites 3 GET requests\n",
      "trade-britanica.trade websites 0 GET requests\n",
      "hfdm.net websites 0 GET requests\n",
      "ctfportugal.pt websites 0 GET requests\n",
      "amc.nl websites 0 GET requests\n",
      "wpcrafter.com websites 0 GET requests\n",
      "gamesgames.com websites 0 GET requests\n",
      "agri-pulse.com websites 0 GET requests\n",
      "trafforsrv.com websites 0 GET requests\n",
      "styleblueprint.com websites 0 GET requests\n",
      "bell.net websites 16 GET requests\n",
      "canjuguichangjia.com websites 0 GET requests\n",
      "llv8.com websites 0 GET requests\n"
     ]
    }
   ],
   "source": [
    "num_of_req(buckets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
